layout: post

title: "DL  알고리즘의 정의와 역사 및 응용"

author: kgm



딥러닝이라는 용어를 정의하기 위해선 그 전에 인공지능, 머신러닝부터 짚고 넘어가야 한다. 딥러닝이 그 안에 있기 때문이다.

​    

인공지능은 인간이 수행하는 학습, 추론, 지각 등의 지능적인 작업을 인공적으로 구현하려는 컴퓨터 공학 분야이다. “인공지능: 현대적 접근법”이라는 책에서는 인공지능을 4가지 영역으로 정의한다. 인간처럼 생각하는 시스템, 인간처럼 행동하는 시스템, 이성적으로 생각하는 시스템, 이성적으로 행동하는 시스템. 인간처럼은 사람이 연구 대상이며 시스템이 사람을 완벽히 따라한다면 성공으로 간주할 수 있다. 이성적인 시스템으로 접근하는 것은 인간 역시도 이성적이지 않다는 가정을 통해 접근하는 것이며 사변적이다. ‘생각하는’ 접근법은 심리학과 논리학을 중심으로 생각 과정이 어떻게 작동하는지를 연구한다. 반면 ‘행동하는’ 접근법은 직관적으로 관찰 가능한 행동을 얼마나 잘 모방하는지에 따라 성공 여부가 결정된다.

​    

머신러닝이라는 용어는 아서 사무엘이 논문에서 처음으로 사용했는데, 그는 이를 컴퓨터가 명시적으로 프로그래밍되지 않고도 학습할 수 있도록 하는 연구 분야라고 정의하였다. 최근 더 많이 사용되는 정의는 톰 미첼의 정의인데, 그는 “작업 T를 수행할 때 경험 E를 통해 성능 측정 방법인 P로 측정했을 때 성능이 향상된다면 이런 컴퓨터 프로그램은 학습했다고 말할 수 있다”라고 프로그램 학습을 정의하였다.

​    

딥러닝은 여러 층을 가진 인공신경망을 사용하여 머신러닝 학습을 수행하는 것으로, 뇌 신경망에서 영감을 받아 만들어진 방식이다. 기존 머신러닝은 학습하려는 데이터의 특징 중에서 어떤 특징을 추출할지를 사람이 직접 찾아내야 했다. 하지만 딥러닝에서는 기계가 스스로 학습하여 데이터에서 특징을 추출한다. 예를 들어 개와 고양이를 구별하는 태스크를 수행할 때, 머신러닝은 사람이 개와 고양이의 특성을 정의하고 데이터세트를 만들고 나면, 컴퓨터가 이를 기반으로 동물을 구별하는 판별식을 결정하였다. 반면 딥러닝은 컴퓨터가 개와 고양이를 보고 스스로 특성을 찾아내고 판별하는 방법이다. 이러한 딥러닝의 특성은 인간이 특징을 추출하기 어려운 데이터에 특히 강점을 보인다.

​    

러닝의 앞에 붙어 있는 딥이라는 말은 신경망의 층이 많으며 그 안에 변수가 많다는 의미이다. (대충 얕은 신경망과 깊은 신경망 짤) 층이 2~3개로 구성된 신경망은 쉘로우 러닝(Shallow Learning)이라고 하며 그 이상부터를 딥러닝이라고 한다. 각 층에는 신경계의 뉴런에 해당하는 노드들이 존재하는데, 이들 각각이 하는 일은 매우 단순하다. 그렇기 때문에 쉘로우 러닝과 같은 방식은 폭넓게 활용되기에는 제한이 있다. 복잡한 문제를 해결하려면 층과 노드 간의 연결 가지 수가 많아져야 한다. 하지만 이때도 문제는 존재한다. 층과 연결가지 수가 증가할수록 연산에 필요한 계산량이 증가하는데, 경우에 따라서는 컴퓨터로 계산하는데 매우 오랜 시간이 걸리거나 아예 계산하지 못할 수도 있다.



딥러닝의 역사:

​    

딥러닝은 머신러닝의 3가지 패러다임 중 하나인 신경 모형 패러다임에서 탄생하였다. 로버트 로센블래트가 1958년에 퍼셉트론 이론을 발표한 이후로 신경 모형 패러다임은 다양한 장애물로 인해 큰 진전을 보지 못하고 있었다.

​    

1965년 이박넨코와 라파는 GMDH(Group Method of Data Handling)라는 딥러닝 시스템을 제시한다. 이는 기존에 사용하던 활성화 함수 대신 ‘Kolmogorov-Gabor’ 다항식을 사용한 활성화 함수가 제시되었다. 이는 처음에는 학습 데이터세트를 통해 은닉층을 확대함으로써 학습 시키고 이후 검증 데이터세트로 불필요한 신경망을 없애버리는 기법이다.

​    

1979년 쿠니히코 후쿠시마는 네오코그니트론 모델을 개발했는데, 이는 처음으로 신경생리학 지식을 접목한 인공신경망이다. 후쿠시마의 연구는 데이비드 허블과 트르스텐 위젤의 고양이 시각 과정에서 뇌의 지각 피질의 동작 구조 연구로부터 영향을 받았는데, 그래서인지 나중에 이미지 인식 분야에 큰 영향을 끼쳤다.

​    

1974년 폴 워보스는 경사감소법 기반의 역전파 기법을 신경망에 적용하였다. 경사감소법은 학습모델의 가중치를 결정하는 방법으로, 가중치를 포함한 피드포워드 함수값이 예상하는 값과 레이블된 실제값과의 차이를 최소화하는 가중치를 찾는 방법이다. 실제값과 예상값의 차이는 에러로 정의되는데, 에러를 제곱한 값을 함수로 나타내면 포물선 모양의 2차 평면에 표현될 수 있다. 해당 모형에서 최저점을 찾는 게 목적이며 이런 과정이 경사진 언덕을 내려가는 것과 같다고 하여 경사감소법이라고 부른다.

​    

그러나 경사감소법에도 문제는 존재하였다. 층이 많은 신경망에서 최적해에 수렴하지 못하고실패하는 문제가 자주 발생하였으며, 또한 경사도가 급격히 감소하거나 계산 영역을 벗어나는 장기 지연 문제도 있었다. 그래서 막상 딥러닝보다는 쉘로우 러닝 문제에서 많이 활용되었다.

​    

1991년에 경사감소법의 문제를 해결하기 위해 셉 호크라이터는 출력층의 정보를 메모리에 저장하여 역전파에 사용하는 장단기 기억법(LTSM: Long Short-Term Memory) 개발하였다. 이는 경사도가 급격히 감소하다가 소멸하는 문제를 해결하였다. 이후 그의 지도학생인 유어겐 슈미츠후버는 1992년에 장단기 기억법을 개선하여 순환신경망(RNN: Recurrent Neural Network)을 만들었다. 이는 결과값을 지도학습으로 역전파하기 전에, 초기부터 중간층까지는 합리적인 비지도학습을 진행하여 불확실한 중간층의 개수를 최소화하는 방법이다.

​    

2006년 제프리 힌튼, 사이먼 오신데로, 이-화이 테는 심층신뢰망(DBN: Deep Belief Network)을 개발하였다. 이는 순환신경망과 유사한데, 많은 전문가들은 해당 알고리즘이 딥러닝을 다시 부흥시키는 계기가 되었다고 평가한다. 심층신뢰망은 제한된 볼츠만 머신(RBM: Restricted Boltmann Machine)이라는 사전 학습 방법을 통해 경사감소소멸 문제를 해결하였다. RBM은 볼츠만 머신으로부터 파생되었는데, 이들은 대칭으로 연결된 입력노드와 은닉 노드 중 의미있는 연결이 어느 것인지를 확률적으로 판단한다는 점에서 공통점을 갖는다. 다만 RBM은 입력층에서 은닉층으로의 연결만 허용되지만, 볼츠만 머신은 층 내부의 노드 간에도 연결이 가능하다는 점에서 다르다. RBM 역시 에러의 정보 손실을 최소화하는 게 목적이다. 

​    

2010년대 들어서 ReLU라는 활성화 함수와 드롭아웃 알고리즘이 개발되면서 딥러닝의 발전이 이루어졌다. 우선 ReLU 함수에 대한 설명부터 하자면, 이는 입력값이 0보다 작으면 함수값이 0이되고, 0보다 크면 ax+b와 같은 1차함수 형태를 띄는 활성화 함수이다. 이런 함수를 사용하게 된 것은 신경과학자들이 뉴런이 신호를 보낼 때 시그모이드 함수보다는 ReLU 형태의 함수를 선호한다는 사실을 밝혀냈기 때문이다. 여기서 영감을 얻어 인공신경망 학자들은 이를 알고리즘에도 적용하기 시작하였다. ReLU 함수는 경사감소소멸 현상을 줄이는 데, 그 이유는 시그모이드 함수의 1차 미분값은 입력값이 커지면 급격히 줄어들지만 ReLU는 일정한 상수값을 유지하기 때문이다.

​    

드롭아웃 알고리즘은 2012는 제프리 힌튼이 과적합 문제를 해결하기 위해 발표한 알고리즘이다. 과정합은 머신러닝에서 노이즈까지 포함되어있는 데이터를 과도하게 학습한 모델이 되려 정확성이 떨어지는 현상을 의미한다. 딥러닝 학습 과정에서 어떤 노드는 이전 층에 있는 어떤 특정 노드의 출력값에 민감히 반응할 때가 있는데, 이 둘이 연결되면 과적합 문제를 유발할 가능성이 크다. 특히 학습 데이터의 규모가 작을수록 더 그렇다. 드롭아웃 알고리즘은 이런 연결을 배제해서 과적합을 줄이다. 그 개념에 대해서 설명하자면, 먼저 각층의 노드를 제거할 확률을 정하는데 보통 P라고 부르며 0.5를 사용한다. P값에 맞게 각층의 노드를 임의로 제거한 후 축소된 신경망으로 피드포워드 기반의 역전파 방식으로 학습한다. 학습된 후 테스트를 할 때는 원래대로 모든 노드를 고려하고 노드마다 가지고 있는 가중치에 P값을 곱한다. 이는 앞 단계에서 확률 P로 드롭아웃된 노드로 학습한 결과를 보상하는 것이다.

​    

​    